{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text-Conditioned 28×28 Diffusion (MNIST-style)\n",
    "\n",
    "Minimal notebook to train and demo a tiny text-conditioned diffusion model that generates 28×28 grayscale images (MNIST style). Intended for fast iteration and interview demos; keep batch/steps small for a quick run, or bump them for quality.\n",
    "\n",
    "**Contents**\n",
    "- Optional lightweight installs\n",
    "- Data: MNIST + simple text prompts\n",
    "- Model: small text encoder + UNet with FiLM\n",
    "- Diffusion training loop (classifier-free guidance ready)\n",
    "- Sampling with adjustable guidance scale and step count\n",
    "- Quick visualization grid\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-27T13:17:08.433724Z",
     "iopub.status.busy": "2025-12-27T13:17:08.433014Z",
     "iopub.status.idle": "2025-12-27T13:17:08.437919Z",
     "shell.execute_reply": "2025-12-27T13:17:08.437186Z",
     "shell.execute_reply.started": "2025-12-27T13:17:08.433690Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Optional: install dependencies (usually available in most ML envs)\n",
    "# !pip install torch torchvision tqdm matplotlib\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-27T13:17:08.439465Z",
     "iopub.status.busy": "2025-12-27T13:17:08.439172Z",
     "iopub.status.idle": "2025-12-27T13:17:08.457606Z",
     "shell.execute_reply": "2025-12-27T13:17:08.456985Z",
     "shell.execute_reply.started": "2025-12-27T13:17:08.439443Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import os\n",
    "import random\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# -----------------\n",
    "# Speed preset\n",
    "# -----------------\n",
    "FAST_MODE = True  # set False for max quality\n",
    "\n",
    "# Device / seed\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device, '| GPUs:', torch.cuda.device_count())\n",
    "\n",
    "# GPU perf toggles (help a lot on T4)\n",
    "if torch.cuda.is_available():\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    torch.backends.cuda.matmul.allow_tf32 = True\n",
    "    torch.backends.cudnn.allow_tf32 = True\n",
    "    try:\n",
    "        torch.set_float32_matmul_precision('high')\n",
    "    except Exception:\n",
    "        pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-27T13:17:08.458748Z",
     "iopub.status.busy": "2025-12-27T13:17:08.458522Z",
     "iopub.status.idle": "2025-12-27T13:17:14.307801Z",
     "shell.execute_reply": "2025-12-27T13:17:14.307043Z",
     "shell.execute_reply.started": "2025-12-27T13:17:08.458728Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26.4M/26.4M [00:01<00:00, 13.4MB/s]\n",
      "100%|██████████| 29.5k/29.5k [00:00<00:00, 274kB/s]\n",
      "100%|██████████| 4.42M/4.42M [00:00<00:00, 5.01MB/s]\n",
      "100%|██████████| 5.15k/5.15k [00:00<00:00, 12.7MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 120000 batch_size: 256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Data: MNIST + FashionMNIST with text prompts\n",
    "# We train on (image, prompt) pairs so the model learns real text conditioning.\n",
    "\n",
    "MNIST_NAMES = [\n",
    "    \"zero\", \"one\", \"two\", \"three\", \"four\",\n",
    "    \"five\", \"six\", \"seven\", \"eight\", \"nine\",\n",
    "]\n",
    "FASHION_NAMES = [\n",
    "    \"t-shirt/top\", \"trouser\", \"pullover\", \"dress\", \"coat\",\n",
    "    \"sandal\", \"shirt\", \"sneaker\", \"bag\", \"ankle boot\",\n",
    "]\n",
    "\n",
    "MNIST_TEMPLATES = [\n",
    "    \"digit {name}\",\n",
    "    \"handwritten digit {name}\",\n",
    "]\n",
    "FASHION_TEMPLATES = [\n",
    "    \"fashion {name}\",\n",
    "    \"clothing {name}\",\n",
    "]\n",
    "\n",
    "def prompt_mnist(y: int) -> str:\n",
    "    name = MNIST_NAMES[int(y)]\n",
    "    return random.choice(MNIST_TEMPLATES).format(name=name)\n",
    "\n",
    "def prompt_fashion(y: int) -> str:\n",
    "    name = FASHION_NAMES[int(y)]\n",
    "    return random.choice(FASHION_TEMPLATES).format(name=name)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,)),  # [-1,1]\n",
    "])\n",
    "\n",
    "class PromptedDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, base_ds, prompt_fn):\n",
    "        self.base_ds = base_ds\n",
    "        self.prompt_fn = prompt_fn\n",
    "    def __len__(self):\n",
    "        return len(self.base_ds)\n",
    "    def __getitem__(self, idx):\n",
    "        x, y = self.base_ds[idx]\n",
    "        return x, self.prompt_fn(y)\n",
    "\n",
    "mnist_train = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "fashion_train = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n",
    "\n",
    "use_dataset = 'both'  # 'mnist' | 'fashion' | 'both'\n",
    "if use_dataset == 'mnist':\n",
    "    train_ds = PromptedDataset(mnist_train, prompt_mnist)\n",
    "elif use_dataset == 'fashion':\n",
    "    train_ds = PromptedDataset(fashion_train, prompt_fashion)\n",
    "else:\n",
    "    train_ds = torch.utils.data.ConcatDataset([\n",
    "        PromptedDataset(mnist_train, prompt_mnist),\n",
    "        PromptedDataset(fashion_train, prompt_fashion),\n",
    "    ])\n",
    "\n",
    "batch_size = (512 if FAST_MODE else 256) if torch.cuda.is_available() else 128\n",
    "print('Dataset size:', len(train_ds), 'batch_size:', batch_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-27T13:17:14.309960Z",
     "iopub.status.busy": "2025-12-27T13:17:14.309557Z",
     "iopub.status.idle": "2025-12-27T13:17:14.498363Z",
     "shell.execute_reply": "2025-12-27T13:17:14.497748Z",
     "shell.execute_reply.started": "2025-12-27T13:17:14.309937Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Building blocks: time embedding, text encoder, FiLM-UNet\n",
    "\n",
    "@dataclass\n",
    "class DiffusionConfig:\n",
    "    img_size: int = 28\n",
    "\n",
    "    # model\n",
    "    base_channels: int = 32  # FAST default\n",
    "    channel_mults: tuple = (1, 2, 2)\n",
    "    text_dim: int = 128\n",
    "    time_dim: int = 128\n",
    "    use_attn: bool = False\n",
    "    attn_heads: int = 4\n",
    "    num_layers_text: int = 2\n",
    "    dropout: float = 0.1\n",
    "\n",
    "    # diffusion\n",
    "    timesteps: int = 200\n",
    "    schedule: str = 'cosine'  # 'cosine' | 'linear'\n",
    "    beta_start: float = 1e-4\n",
    "    beta_end: float = 0.02\n",
    "\n",
    "def sinusoidal_time_embedding(timesteps: torch.Tensor, dim: int) -> torch.Tensor:\n",
    "    half = dim // 2\n",
    "    freqs = torch.exp(-math.log(10000) * torch.arange(half, device=timesteps.device) / (half - 1))\n",
    "    args = timesteps[:, None] * freqs[None, :]\n",
    "    emb = torch.cat([torch.sin(args), torch.cos(args)], dim=-1)\n",
    "    return emb\n",
    "\n",
    "class TextEncoder(nn.Module):\n",
    "    def __init__(self, vocab_size: int, emb_dim: int, hidden_dim: int, num_layers: int = 2, dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_dim)\n",
    "        self.gru = nn.GRU(emb_dim, hidden_dim, num_layers=num_layers, batch_first=True, bidirectional=True, dropout=dropout)\n",
    "        self.proj = nn.Sequential(nn.Linear(hidden_dim * 2, hidden_dim), nn.SiLU(), nn.Linear(hidden_dim, hidden_dim))\n",
    "    def forward(self, tokens, lengths):\n",
    "        x = self.embedding(tokens)\n",
    "        packed = nn.utils.rnn.pack_padded_sequence(x, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        out, _ = self.gru(packed)\n",
    "        out, _ = nn.utils.rnn.pad_packed_sequence(out, batch_first=True)\n",
    "        # take last valid timestep per sequence\n",
    "        idx = (lengths - 1).clamp(min=0)\n",
    "        last = out[torch.arange(out.size(0)), idx]\n",
    "        return self.proj(last)\n",
    "\n",
    "class FiLM(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(in_dim, out_dim * 2)\n",
    "    def forward(self, x, cond):\n",
    "        scale, shift = self.linear(cond).chunk(2, dim=1)\n",
    "        return x * (1 + scale[:, :, None, None]) + shift[:, :, None, None]\n",
    "\n",
    "class SelfAttention2d(nn.Module):\n",
    "    def __init__(self, channels: int, heads: int = 4):\n",
    "        super().__init__()\n",
    "        assert channels % heads == 0, 'channels must be divisible by heads'\n",
    "        self.heads = heads\n",
    "        self.norm = nn.GroupNorm(8, channels)\n",
    "        self.qkv = nn.Conv2d(channels, channels * 3, 1)\n",
    "        self.proj = nn.Conv2d(channels, channels, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, h, w = x.shape\n",
    "        x_in = x\n",
    "        x = self.norm(x)\n",
    "        qkv = self.qkv(x)\n",
    "        q, k, v = qkv.chunk(3, dim=1)\n",
    "\n",
    "        # (B, heads, C//heads, HW)\n",
    "        q = q.view(b, self.heads, c // self.heads, h * w)\n",
    "        k = k.view(b, self.heads, c // self.heads, h * w)\n",
    "        v = v.view(b, self.heads, c // self.heads, h * w)\n",
    "\n",
    "        q = q.permute(0, 1, 3, 2)  # (B, heads, HW, d)\n",
    "        k = k.permute(0, 1, 2, 3)  # (B, heads, d, HW)\n",
    "        attn = (q @ k) / math.sqrt(c // self.heads)\n",
    "        attn = attn.softmax(dim=-1)\n",
    "\n",
    "        v = v.permute(0, 1, 3, 2)  # (B, heads, HW, d)\n",
    "        out = attn @ v\n",
    "        out = out.permute(0, 1, 3, 2).contiguous().view(b, c, h, w)\n",
    "        out = self.proj(out)\n",
    "        return x_in + out\n",
    "\n",
    "\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, time_dim, text_dim):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_ch, out_ch, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(out_ch, out_ch, 3, padding=1)\n",
    "        self.time_film = FiLM(time_dim, out_ch)\n",
    "        self.text_film = FiLM(text_dim, out_ch)\n",
    "        self.act = nn.SiLU()\n",
    "        self.norm1 = nn.GroupNorm(8, out_ch)\n",
    "        self.norm2 = nn.GroupNorm(8, out_ch)\n",
    "        self.skip = nn.Conv2d(in_ch, out_ch, 1) if in_ch != out_ch else nn.Identity()\n",
    "\n",
    "    def forward(self, x, t_emb, txt_emb):\n",
    "        h = self.act(self.norm1(self.conv1(x)))\n",
    "        h = self.time_film(h, t_emb)\n",
    "        h = self.text_film(h, txt_emb)\n",
    "        h = self.act(self.norm2(self.conv2(h)))\n",
    "        return h + self.skip(x)\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, cfg: DiffusionConfig, text_vocab: int):\n",
    "        super().__init__()\n",
    "        ch = cfg.base_channels\n",
    "        self.text_encoder = TextEncoder(\n",
    "            text_vocab,\n",
    "            emb_dim=cfg.text_dim,\n",
    "            hidden_dim=cfg.text_dim,\n",
    "            num_layers=cfg.num_layers_text,\n",
    "            dropout=cfg.dropout,\n",
    "        )\n",
    "        self.null_text = nn.Parameter(torch.zeros(cfg.text_dim))\n",
    "\n",
    "        self.time_mlp = nn.Sequential(\n",
    "            nn.Linear(cfg.time_dim, cfg.time_dim * 4), nn.SiLU(), nn.Linear(cfg.time_dim * 4, cfg.time_dim)\n",
    "        )\n",
    "\n",
    "        Attn = (lambda c: SelfAttention2d(c, heads=cfg.attn_heads)) if cfg.use_attn else (lambda c: nn.Identity())\n",
    "\n",
    "        # Down\n",
    "        self.enc1 = ResBlock(1, ch, cfg.time_dim, cfg.text_dim)\n",
    "        self.enc2 = ResBlock(ch, ch * cfg.channel_mults[1], cfg.time_dim, cfg.text_dim)\n",
    "        self.enc2_attn = Attn(ch * cfg.channel_mults[1])\n",
    "        self.enc3 = ResBlock(ch * cfg.channel_mults[1], ch * cfg.channel_mults[2], cfg.time_dim, cfg.text_dim)\n",
    "        self.pool = nn.AvgPool2d(2)\n",
    "\n",
    "        # Bottleneck\n",
    "        self.mid = ResBlock(ch * cfg.channel_mults[2], ch * cfg.channel_mults[2], cfg.time_dim, cfg.text_dim)\n",
    "        self.mid_attn = Attn(ch * cfg.channel_mults[2])\n",
    "\n",
    "        # Up\n",
    "        self.up1 = nn.ConvTranspose2d(ch * cfg.channel_mults[2], ch * cfg.channel_mults[1], 2, stride=2)\n",
    "        self.dec1 = ResBlock(ch * cfg.channel_mults[1] * 2, ch * cfg.channel_mults[1], cfg.time_dim, cfg.text_dim)\n",
    "        self.dec1_attn = Attn(ch * cfg.channel_mults[1])\n",
    "        self.up2 = nn.ConvTranspose2d(ch * cfg.channel_mults[1], ch, 2, stride=2)\n",
    "        self.dec2 = ResBlock(ch * 2, ch, cfg.time_dim, cfg.text_dim)\n",
    "\n",
    "        self.out = nn.Conv2d(ch, 1, 1)\n",
    "\n",
    "    def forward(self, x, t, txt_tokens, txt_lens, drop_text_prob: float = 0.1):\n",
    "        t_emb = self.time_mlp(sinusoidal_time_embedding(t, self.time_mlp[0].in_features))\n",
    "\n",
    "        # --- classifier-free guidance support ---\n",
    "        # During sampling we need a true unconditional path even in eval(),\n",
    "        # so drop_text_prob==1.0 forces the null embedding.\n",
    "        if drop_text_prob >= 1.0:\n",
    "            txt_emb = self.null_text[None, :].expand(x.size(0), -1)\n",
    "        else:\n",
    "            txt_emb = self.text_encoder(txt_tokens, txt_lens)\n",
    "            if self.training and drop_text_prob > 0.0:\n",
    "                mask = (torch.rand(txt_emb.size(0), device=txt_emb.device) < drop_text_prob).float()[:, None]\n",
    "                txt_emb = txt_emb * (1 - mask) + self.null_text[None, :] * mask\n",
    "\n",
    "        e1 = self.enc1(x, t_emb, txt_emb)\n",
    "        e2 = self.enc2(self.pool(e1), t_emb, txt_emb)\n",
    "        e2 = self.enc2_attn(e2)\n",
    "        e3 = self.enc3(self.pool(e2), t_emb, txt_emb)\n",
    "\n",
    "        m = self.mid(e3, t_emb, txt_emb)\n",
    "        m = self.mid_attn(m)\n",
    "\n",
    "        d1 = self.up1(m)\n",
    "        d1 = torch.cat([d1, e2], dim=1)\n",
    "        d1 = self.dec1(d1, t_emb, txt_emb)\n",
    "        d1 = self.dec1_attn(d1)\n",
    "        d2 = self.up2(d1)\n",
    "        d2 = torch.cat([d2, e1], dim=1)\n",
    "        d2 = self.dec2(d2, t_emb, txt_emb)\n",
    "        return self.out(d2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-27T13:17:14.499504Z",
     "iopub.status.busy": "2025-12-27T13:17:14.499193Z",
     "iopub.status.idle": "2025-12-27T13:17:14.526282Z",
     "shell.execute_reply": "2025-12-27T13:17:14.525574Z",
     "shell.execute_reply.started": "2025-12-27T13:17:14.499474Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 27\n"
     ]
    }
   ],
   "source": [
    "# Tokenizer helpers (simple character-level; robust for small prompt vocab)\n",
    "\n",
    "class SimpleCharTokenizer:\n",
    "    def __init__(self, texts, pad_token='<pad>', unk_token='<unk>'):\n",
    "        chars = sorted(list({c for t in texts for c in t.lower()}))\n",
    "        self.pad_token = pad_token\n",
    "        self.unk_token = unk_token\n",
    "        self.itos = [pad_token, unk_token] + chars\n",
    "        self.stoi = {c: i for i, c in enumerate(self.itos)}\n",
    "\n",
    "    @property\n",
    "    def vocab_size(self):\n",
    "        return len(self.itos)\n",
    "\n",
    "    def encode(self, text: str, max_len: int = 32):\n",
    "        text = text.lower()\n",
    "        ids = [self.stoi.get(c, self.stoi[self.unk_token]) for c in text[:max_len]]\n",
    "        length = len(ids)\n",
    "        if length < max_len:\n",
    "            ids += [self.stoi[self.pad_token]] * (max_len - length)\n",
    "        return torch.tensor(ids, dtype=torch.long), torch.tensor(length, dtype=torch.long)\n",
    "\n",
    "    def encode_batch(self, texts, max_len: int = 32):\n",
    "        toks, lens = zip(*[self.encode(t, max_len=max_len) for t in texts])\n",
    "        return torch.stack(toks), torch.stack(lens)\n",
    "\n",
    "# Build tokenizer vocab from both datasets' templates\n",
    "all_prompts = []\n",
    "for i in range(10):\n",
    "    for tpl in MNIST_TEMPLATES:\n",
    "        all_prompts.append(tpl.format(name=MNIST_NAMES[i]))\n",
    "    for tpl in FASHION_TEMPLATES:\n",
    "        all_prompts.append(tpl.format(name=FASHION_NAMES[i]))\n",
    "\n",
    "tokenizer = SimpleCharTokenizer(all_prompts)\n",
    "print('Vocab size:', tokenizer.vocab_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-27T13:17:14.527580Z",
     "iopub.status.busy": "2025-12-27T13:17:14.527203Z",
     "iopub.status.idle": "2025-12-27T13:17:14.550578Z",
     "shell.execute_reply": "2025-12-27T13:17:14.549985Z",
     "shell.execute_reply.started": "2025-12-27T13:17:14.527550Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train batches: 469\n"
     ]
    }
   ],
   "source": [
    "# Diffusion utilities\n",
    "\n",
    "def cosine_beta_schedule(timesteps: int, s: float = 0.008):\n",
    "    # From Nichol & Dhariwal 2021 (Improved DDPM)\n",
    "    steps = timesteps + 1\n",
    "    x = torch.linspace(0, timesteps, steps, dtype=torch.float32)\n",
    "    alphas_cum = torch.cos(((x / timesteps) + s) / (1 + s) * math.pi * 0.5) ** 2\n",
    "    alphas_cum = alphas_cum / alphas_cum[0]\n",
    "    betas = 1 - (alphas_cum[1:] / alphas_cum[:-1])\n",
    "    return betas.clamp(1e-5, 0.999)\n",
    "\n",
    "\n",
    "class SimpleDiffusion(nn.Module):\n",
    "    \"\"\"DDPM/DDIM utilities with schedule tensors registered as buffers (so .to(device) works).\"\"\"\n",
    "    def __init__(self, cfg: DiffusionConfig):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "\n",
    "        if cfg.schedule == 'cosine':\n",
    "            betas = cosine_beta_schedule(cfg.timesteps)\n",
    "        else:\n",
    "            betas = torch.linspace(cfg.beta_start, cfg.beta_end, cfg.timesteps, dtype=torch.float32)\n",
    "\n",
    "        alphas = 1.0 - betas\n",
    "        alphas_cum = torch.cumprod(alphas, dim=0)\n",
    "\n",
    "        self.register_buffer('betas', betas)\n",
    "        self.register_buffer('alphas', alphas)\n",
    "        self.register_buffer('alphas_cum', alphas_cum)\n",
    "\n",
    "    def sample_timesteps(self, batch_size: int, device: Optional[torch.device] = None):\n",
    "        if device is None:\n",
    "            device = self.betas.device\n",
    "        return torch.randint(0, self.cfg.timesteps, (batch_size,), device=device)\n",
    "\n",
    "    def add_noise(self, x0, t, noise):\n",
    "        # t: (B,) long on same device as buffers\n",
    "        sqrt_ac = self.alphas_cum[t].sqrt()[:, None, None, None]\n",
    "        sqrt_one_minus_ac = (1 - self.alphas_cum[t]).sqrt()[:, None, None, None]\n",
    "        return sqrt_ac * x0 + sqrt_one_minus_ac * noise\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _predict_eps_cfg(self, model, x, t: int, txt_tokens, txt_lens, guidance_scale: float):\n",
    "        # classifier-free guidance\n",
    "        t_batch = torch.full((x.size(0),), t, device=x.device, dtype=torch.long)\n",
    "        eps_text = model(x, t_batch, txt_tokens, txt_lens, drop_text_prob=0.0)\n",
    "        eps_null = model(x, t_batch, txt_tokens, txt_lens, drop_text_prob=1.0)\n",
    "        return eps_null + guidance_scale * (eps_text - eps_null)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def p_sample(self, model, x, t: int, txt_tokens, txt_lens, guidance_scale: float = 2.0):\n",
    "        \"\"\"Ancestral DDPM step (kept for reference).\"\"\"\n",
    "        eps = self._predict_eps_cfg(model, x, t, txt_tokens, txt_lens, guidance_scale)\n",
    "        beta_t = self.betas[t]\n",
    "        alpha_t = self.alphas[t]\n",
    "        alpha_cum_t = self.alphas_cum[t]\n",
    "        mean = (1 / alpha_t.sqrt()) * (x - beta_t / (1 - alpha_cum_t).sqrt() * eps)\n",
    "        if t == 0:\n",
    "            return mean\n",
    "        noise = torch.randn_like(x)\n",
    "        return mean + beta_t.sqrt() * noise\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def ddim_step(self, model, x, t: int, t_prev: int, txt_tokens, txt_lens, guidance_scale: float = 2.0, eta: float = 0.0):\n",
    "        \"\"\"DDIM step that supports skipping timesteps cleanly.\"\"\"\n",
    "        eps = self._predict_eps_cfg(model, x, t, txt_tokens, txt_lens, guidance_scale)\n",
    "\n",
    "        ac_t = self.alphas_cum[t]\n",
    "        ac_prev = self.alphas_cum[t_prev] if t_prev >= 0 else torch.tensor(1.0, device=x.device)\n",
    "\n",
    "        # predict x0\n",
    "        x0 = (x - (1 - ac_t).sqrt() * eps) / ac_t.sqrt()\n",
    "        x0 = x0.clamp(-1, 1)\n",
    "\n",
    "        # DDIM variance control\n",
    "        if t_prev < 0:\n",
    "            return x0\n",
    "\n",
    "        sigma = eta * torch.sqrt((1 - ac_prev) / (1 - ac_t) * (1 - ac_t / ac_prev))\n",
    "        noise = torch.randn_like(x) if eta > 0 else torch.zeros_like(x)\n",
    "\n",
    "        dir_xt = (1 - ac_prev - sigma**2).sqrt() * eps\n",
    "        x_prev = ac_prev.sqrt() * x0 + dir_xt + sigma * noise\n",
    "        return x_prev\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def sample(self, model, txt_tokens, txt_lens, steps: int = 40, guidance_scale: float = 2.0, eta: float = 0.0):\n",
    "        model.eval()\n",
    "        b = txt_tokens.size(0)\n",
    "        x = torch.randn(b, 1, self.cfg.img_size, self.cfg.img_size, device=txt_tokens.device)\n",
    "\n",
    "        # choose a schedule of timesteps (descending)\n",
    "        steps = int(steps)\n",
    "        steps = max(2, min(steps, self.cfg.timesteps))\n",
    "        ts = torch.linspace(self.cfg.timesteps - 1, 0, steps, device=txt_tokens.device).long()\n",
    "\n",
    "        for i in range(len(ts)):\n",
    "            t = int(ts[i].item())\n",
    "            t_prev = int(ts[i + 1].item()) if i + 1 < len(ts) else -1\n",
    "            x = self.ddim_step(model, x, t, t_prev, txt_tokens, txt_lens, guidance_scale=guidance_scale, eta=eta)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "def collate_batch(batch):\n",
    "    imgs, prompts = zip(*batch)\n",
    "    imgs = torch.stack(imgs)\n",
    "    toks, lens = tokenizer.encode_batch(prompts, max_len=32)\n",
    "    return imgs, toks, lens, list(prompts)\n",
    "\n",
    "# DataLoader (now that tokenizer + collate exist)\n",
    "num_workers = 4 if torch.cuda.is_available() else 0\n",
    "train_loader = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=(num_workers > 0),\n",
    "    prefetch_factor=4 if num_workers > 0 else None,\n",
    "    collate_fn=collate_batch,\n",
    ")\n",
    "print('Train batches:', len(train_loader), '| num_workers:', num_workers)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-27T13:17:14.551559Z",
     "iopub.status.busy": "2025-12-27T13:17:14.551339Z",
     "iopub.status.idle": "2025-12-27T14:22:59.104844Z",
     "shell.execute_reply": "2025-12-27T14:22:59.104161Z",
     "shell.execute_reply.started": "2025-12-27T13:17:14.551538Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using DataParallel on 2 GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_55/1791650000.py:33: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=torch.cuda.is_available())\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74794da53f65401db215d654fabca16d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train:   0%|          | 0/30000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_55/1791650000.py:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training steps: 30000\n"
     ]
    }
   ],
   "source": [
    "# Model + training loop\n",
    "\n",
    "cfg = DiffusionConfig()\n",
    "\n",
    "# FAST/quality presets\n",
    "if not FAST_MODE:\n",
    "    cfg.base_channels = 64\n",
    "    cfg.use_attn = True\n",
    "    cfg.timesteps = 400\n",
    "else:\n",
    "    cfg.base_channels = 32\n",
    "    cfg.use_attn = False\n",
    "    cfg.timesteps = 200\n",
    "\n",
    "print('Config:', cfg)\n",
    "\n",
    "diffusion = SimpleDiffusion(cfg).to(device)\n",
    "\n",
    "# Note: for this tiny 28×28 model, nn.DataParallel often *slows down*.\n",
    "# We'll default to single-GPU fast path; you can force DataParallel if you want.\n",
    "USE_DATAPARALLEL = False\n",
    "\n",
    "base_model = UNet(cfg, text_vocab=tokenizer.vocab_size).to(device)\n",
    "\n",
    "if USE_DATAPARALLEL and torch.cuda.device_count() > 1:\n",
    "    print('Using DataParallel on', torch.cuda.device_count(), 'GPUs')\n",
    "    model = nn.DataParallel(base_model)\n",
    "else:\n",
    "    model = base_model\n",
    "\n",
    "# channels_last can speed convs on some GPUs\n",
    "if torch.cuda.is_available():\n",
    "    model = model.to(memory_format=torch.channels_last)\n",
    "\n",
    "# optional torch.compile (PyTorch 2.x) - can speed up steady-state\n",
    "USE_COMPILE = FAST_MODE\n",
    "if USE_COMPILE and hasattr(torch, 'compile'):\n",
    "    try:\n",
    "        model = torch.compile(model)\n",
    "        print('torch.compile enabled')\n",
    "    except Exception as e:\n",
    "        print('torch.compile failed:', e)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-4 if FAST_MODE else 1e-4, weight_decay=1e-2)\n",
    "\n",
    "# EMA helps samples look cleaner with the same number of training steps\n",
    "@torch.no_grad()\n",
    "def unwrap(m: nn.Module) -> nn.Module:\n",
    "    return m.module if hasattr(m, 'module') else m\n",
    "\n",
    "@torch.no_grad()\n",
    "def ema_update(ema_model: nn.Module, model: nn.Module, decay: float = 0.999):\n",
    "    src = unwrap(model)\n",
    "    for ema_p, p in zip(ema_model.parameters(), src.parameters()):\n",
    "        ema_p.data.mul_(decay).add_(p.data, alpha=1 - decay)\n",
    "\n",
    "ema_model = UNet(cfg, text_vocab=tokenizer.vocab_size).to(device)\n",
    "ema_model.load_state_dict(unwrap(model).state_dict())\n",
    "ema_decay = 0.999\n",
    "\n",
    "# Mixed precision for speed on T4\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=torch.cuda.is_available())\n",
    "\n",
    "num_steps = 12_000 if FAST_MODE else 50_000\n",
    "log_interval = 200\n",
    "\n",
    "# optional gradient accumulation (lets you use big effective batch without huge VRAM)\n",
    "grad_accum = 1 if FAST_MODE else 2\n",
    "\n",
    "model.train()\n",
    "step = 0\n",
    "pbar = tqdm(total=num_steps, desc='train')\n",
    "while step < num_steps:\n",
    "    for x, tokens, lens, _prompts in train_loader:\n",
    "        x = x.to(device, non_blocking=True)\n",
    "        tokens = tokens.to(device, non_blocking=True)\n",
    "        lens = lens.to(device, non_blocking=True)\n",
    "\n",
    "        # channels_last input (must match model memory_format)\n",
    "        if torch.cuda.is_available():\n",
    "            x = x.contiguous(memory_format=torch.channels_last)\n",
    "\n",
    "        t = diffusion.sample_timesteps(x.size(0), device)\n",
    "        noise = torch.randn_like(x)\n",
    "        x_noisy = diffusion.add_noise(x, t, noise)\n",
    "\n",
    "        # gradient accumulation\n",
    "        if step % grad_accum == 0:\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n",
    "            pred = model(x_noisy, t, tokens, lens, drop_text_prob=0.15)\n",
    "            loss = F.mse_loss(pred, noise)\n",
    "            loss = loss / grad_accum\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        if (step + 1) % grad_accum == 0:\n",
    "            scaler.unscale_(optimizer)\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            ema_update(ema_model, model, decay=ema_decay)\n",
    "\n",
    "        step += 1\n",
    "        pbar.update(1)\n",
    "        if step % log_interval == 0:\n",
    "            pbar.set_postfix(loss=float(loss.detach()) * grad_accum)\n",
    "        if step >= num_steps:\n",
    "            break\n",
    "pbar.close()\n",
    "print('Finished training steps:', step)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-27T14:22:59.106507Z",
     "iopub.status.busy": "2025-12-27T14:22:59.106201Z",
     "iopub.status.idle": "2025-12-27T14:22:59.824831Z",
     "shell.execute_reply": "2025-12-27T14:22:59.824125Z",
     "shell.execute_reply.started": "2025-12-27T14:22:59.106479Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x200 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Sampling demo\n",
    "# Use EMA weights for nicer samples\n",
    "ema_model.eval()\n",
    "\n",
    "# Demo prompts (digits + fashion)\n",
    "prompts = [\n",
    "    \"digit zero\",\n",
    "    \"digit three\",\n",
    "    \"digit seven\",\n",
    "    \"fashion sneaker\",\n",
    "    \"fashion ankle boot\",\n",
    "]\n",
    "\n",
    "tokens = []\n",
    "lens = []\n",
    "for p in prompts:\n",
    "    tok, l = tokenizer.encode(p)\n",
    "    tokens.append(tok)\n",
    "    lens.append(l)\n",
    "tokens = torch.stack(tokens).to(device)\n",
    "lens = torch.stack(lens).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    # try steps=30..60, guidance_scale=1.5..3.0\n",
    "    samples = diffusion.sample(ema_model, tokens, lens, steps=40, guidance_scale=2.0, eta=0.0)\n",
    "\n",
    "imgs = (samples.clamp(-1, 1) * 0.5 + 0.5).cpu()  # back to [0,1]\n",
    "fig, axes = plt.subplots(1, len(prompts), figsize=(len(prompts)*2, 2))\n",
    "for ax, img, p in zip(axes, imgs, prompts):\n",
    "    ax.imshow(img[0], cmap='gray')\n",
    "    ax.axis('off')\n",
    "    ax.set_title(p)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tips / Next steps\n",
    "- Increase `num_steps`, `base_channels`, and train for more iterations for better quality.\n",
    "- Try more diverse prompts by expanding the tokenizer vocabulary (add your own prompt list).\n",
    "- Save/Load: `torch.save(model.state_dict(), 'cfdiffusion.pt')` and load with `model.load_state_dict(torch.load(...))`.\n",
    "- Swap sampler stride logic to use full step schedule for best results; current stride ties `steps` to coarse skipping for speed.\n",
    "- To condition on richer text, swap the GRU for a tiny Transformer encoder.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 31236,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "",
   "name": ""
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
